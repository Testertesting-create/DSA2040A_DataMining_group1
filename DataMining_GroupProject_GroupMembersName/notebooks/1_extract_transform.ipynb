{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5952732",
   "metadata": {},
   "source": [
    "## **Data Cleaning Steps Overview**\n",
    "\n",
    " 1. **Read the raw file** using the correct delimiter (`;`).\n",
    " 2. **Remove empty columns and rows** to handle any trailing semicolons r blank lines.\n",
    " 3. **Save the cleaned data** to the `data/raw/` folder.\n",
    " 4. **Preview the results** by printing the shape and the first few rows of the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48519ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1259, 27)\n",
      "          Timestamp Age  Gender         Country state self_employed  \\\n",
      "0  27/08/2014 11:29  37  Female   United States    IL           NaN   \n",
      "1  27/08/2014 11:29  44       M   United States    IN           NaN   \n",
      "2  27/08/2014 11:29  32    Male          Canada   NaN           NaN   \n",
      "3  27/08/2014 11:29  31    Male  United Kingdom   NaN           NaN   \n",
      "4  27/08/2014 11:30  31    Male   United States    TX           NaN   \n",
      "\n",
      "  family_history treatment work_interfere    no_employees  ...  \\\n",
      "0             No       Yes          Often          WTD-25  ...   \n",
      "1             No        No         Rarely  More than 1000  ...   \n",
      "2             No        No         Rarely          WTD-25  ...   \n",
      "3            Yes       Yes          Often          26-100  ...   \n",
      "4             No        No          Never         100-500  ...   \n",
      "\n",
      "                leave mental_health_consequence phys_health_consequence  \\\n",
      "0       Somewhat easy                        No                      No   \n",
      "1          Don't know                     Maybe                      No   \n",
      "2  Somewhat difficult                        No                      No   \n",
      "3  Somewhat difficult                       Yes                     Yes   \n",
      "4          Don't know                        No                      No   \n",
      "\n",
      "      coworkers supervisor mental_health_interview phys_health_interview  \\\n",
      "0  Some of them        Yes                      No                 Maybe   \n",
      "1            No         No                      No                    No   \n",
      "2           Yes        Yes                     Yes                   Yes   \n",
      "3  Some of them         No                   Maybe                 Maybe   \n",
      "4  Some of them        Yes                     Yes                   Yes   \n",
      "\n",
      "  mental_vs_physical obs_consequence comments  \n",
      "0                Yes              No      NaN  \n",
      "1         Don't know              No      NaN  \n",
      "2                 No              No      NaN  \n",
      "3                 No             Yes      NaN  \n",
      "4         Don't know              No      NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the raw dataset\n",
    "raw_path = 'C:/Users/HP/iCloudDrive/school/DSA 2040/Project/DSA2040A_DataMining_group1/OSMI Mental Health Tech Survey 2014 Dataset.csv'\n",
    "cleaned_path = '../data/raw/OSMI_Mental_Health_Cleaned.csv'\n",
    "\n",
    "# 1. Read the raw CSV with the correct delimiter\n",
    "df = pd.read_csv(raw_path, delimiter=';', dtype=str)\n",
    "\n",
    "# 2. Remove any columns that are completely empty (sometimes caused by trailing delimiters)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# 3. Remove any rows that are completely empty\n",
    "df = df.dropna(axis=0, how='all')\n",
    "\n",
    "# 4. Save the cleaned file (still semicolon-delimited for now)\n",
    "df.to_csv(cleaned_path, index=False, sep=';')\n",
    "\n",
    "# 5. Preview the data\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22cbf9",
   "metadata": {},
   "source": [
    " ## 2. Data Transformation\n",
    " In this step, we will perform the following data transformation tasks:\n",
    "  - Standardize column names (e.g., make lowercase, replace spaces with underscores)\n",
    "- Normalize categorical values (e.g., gender, country)\n",
    "- Handle missing values appropriately\n",
    "- Convert data types where necessary (e.g., age to integer)\n",
    "- Create any new features if needed for analysis\n",
    "- Save the transformed data for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba389cd7",
   "metadata": {},
   "source": [
    "## 2.1 Standardize Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca151eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Timestamp                       0\n",
      "Age                             0\n",
      "Gender                          0\n",
      "Country                         0\n",
      "state                         515\n",
      "self_employed                  18\n",
      "family_history                  0\n",
      "treatment                       0\n",
      "work_interfere                264\n",
      "no_employees                    0\n",
      "remote_work                     0\n",
      "tech_company                    0\n",
      "benefits                      408\n",
      "care_options                  314\n",
      "wellness_program              188\n",
      "seek_help                     363\n",
      "anonymity                     819\n",
      "leave                         563\n",
      "mental_health_consequence       0\n",
      "phys_health_consequence         0\n",
      "coworkers                       0\n",
      "supervisor                      0\n",
      "mental_health_interview         0\n",
      "phys_health_interview           0\n",
      "mental_vs_physical            576\n",
      "obs_consequence                 0\n",
      "comments                     1096\n",
      "dtype: int64\n",
      "\n",
      "Total missing values in dataset: 5124\n",
      "\n",
      "Percentage of missing values per column:\n",
      "Timestamp                     0.00\n",
      "Age                           0.00\n",
      "Gender                        0.00\n",
      "Country                       0.00\n",
      "state                        40.91\n",
      "self_employed                 1.43\n",
      "family_history                0.00\n",
      "treatment                     0.00\n",
      "work_interfere               20.97\n",
      "no_employees                  0.00\n",
      "remote_work                   0.00\n",
      "tech_company                  0.00\n",
      "benefits                     32.41\n",
      "care_options                 24.94\n",
      "wellness_program             14.93\n",
      "seek_help                    28.83\n",
      "anonymity                    65.05\n",
      "leave                        44.72\n",
      "mental_health_consequence     0.00\n",
      "phys_health_consequence       0.00\n",
      "coworkers                     0.00\n",
      "supervisor                    0.00\n",
      "mental_health_interview       0.00\n",
      "phys_health_interview         0.00\n",
      "mental_vs_physical           45.75\n",
      "obs_consequence               0.00\n",
      "comments                     87.05\n",
      "dtype: float64\n",
      "\n",
      "Sample rows with missing data:\n",
      "          Timestamp Age  Gender         Country state self_employed  \\\n",
      "0  27/08/2014 11:29  37  Female   United States    IL           NaN   \n",
      "1  27/08/2014 11:29  44       M   United States    IN           NaN   \n",
      "2  27/08/2014 11:29  32    Male          Canada   NaN           NaN   \n",
      "3  27/08/2014 11:29  31    Male  United Kingdom   NaN           NaN   \n",
      "4  27/08/2014 11:30  31    Male   United States    TX           NaN   \n",
      "\n",
      "  family_history treatment work_interfere    no_employees  ...  \\\n",
      "0             No       Yes          Often          WTD-25  ...   \n",
      "1             No        No         Rarely  More than 1000  ...   \n",
      "2             No        No         Rarely          WTD-25  ...   \n",
      "3            Yes       Yes          Often          26-100  ...   \n",
      "4             No        No          Never         100-500  ...   \n",
      "\n",
      "                leave mental_health_consequence phys_health_consequence  \\\n",
      "0       Somewhat easy                        No                      No   \n",
      "1                 NaN                     Maybe                      No   \n",
      "2  Somewhat difficult                        No                      No   \n",
      "3  Somewhat difficult                       Yes                     Yes   \n",
      "4                 NaN                        No                      No   \n",
      "\n",
      "      coworkers supervisor mental_health_interview phys_health_interview  \\\n",
      "0  Some of them        Yes                      No                 Maybe   \n",
      "1            No         No                      No                    No   \n",
      "2           Yes        Yes                     Yes                   Yes   \n",
      "3  Some of them         No                   Maybe                 Maybe   \n",
      "4  Some of them        Yes                     Yes                   Yes   \n",
      "\n",
      "  mental_vs_physical obs_consequence comments  \n",
      "0                Yes              No      NaN  \n",
      "1                NaN              No      NaN  \n",
      "2                 No              No      NaN  \n",
      "3                 No             Yes      NaN  \n",
      "4                NaN              No      NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Define all known missing value indicators\n",
    "missing_vals = ['NA', 'N/A', 'n/a', 'na', 'Not sure', \"Don't know\", '', ' ']\n",
    "\n",
    "# 2. Replace all such values with np.nan across the entire DataFrame\n",
    "df_clean = df.replace(missing_vals, np.nan)\n",
    "\n",
    "# 3. View missing value counts per column\n",
    "print(\"Missing values per column:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# 4. View total missing values in the dataset\n",
    "print(f\"\\nTotal missing values in dataset: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# 5. (Optional) View percentage of missing values per column\n",
    "print(\"\\nPercentage of missing values per column:\")\n",
    "print((df_clean.isnull().mean() * 100).round(2))\n",
    "\n",
    "# 6. Show a sample of rows with missing data\n",
    "print(\"\\nSample rows with missing data:\")\n",
    "print(df_clean[df_clean.isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126450e",
   "metadata": {},
   "source": [
    "# # 2.2 Here we clean the 'Age' column:\n",
    " Convert the 'Age' column to numeric values, setting any invalid entries to NaN.\n",
    "- Remove rows where age is outside the range 15 to 80.\n",
    "- Count and report how many rows were removed due to implausible ages.\n",
    "- Check for duplicate rows, remove them if found, and report how many were removed.\n",
    "- Finally, display information and a preview of the cleaned DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c020eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 8 rows with implausible ages.\n",
      "Removed 1 duplicate rows.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1250 entries, 0 to 1258\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Timestamp                  1250 non-null   object\n",
      " 1   Age                        1250 non-null   int64 \n",
      " 2   Gender                     1250 non-null   object\n",
      " 3   Country                    1250 non-null   object\n",
      " 4   state                      738 non-null    object\n",
      " 5   self_employed              1232 non-null   object\n",
      " 6   family_history             1250 non-null   object\n",
      " 7   treatment                  1250 non-null   object\n",
      " 8   work_interfere             988 non-null    object\n",
      " 9   no_employees               1250 non-null   object\n",
      " 10  remote_work                1250 non-null   object\n",
      " 11  tech_company               1250 non-null   object\n",
      " 12  benefits                   843 non-null    object\n",
      " 13  care_options               937 non-null    object\n",
      " 14  wellness_program           1063 non-null   object\n",
      " 15  seek_help                  887 non-null    object\n",
      " 16  anonymity                  435 non-null    object\n",
      " 17  leave                      690 non-null    object\n",
      " 18  mental_health_consequence  1250 non-null   object\n",
      " 19  phys_health_consequence    1250 non-null   object\n",
      " 20  coworkers                  1250 non-null   object\n",
      " 21  supervisor                 1250 non-null   object\n",
      " 22  mental_health_interview    1250 non-null   object\n",
      " 23  phys_health_interview      1250 non-null   object\n",
      " 24  mental_vs_physical         676 non-null    object\n",
      " 25  obs_consequence            1250 non-null   object\n",
      " 26  comments                   161 non-null    object\n",
      "dtypes: int64(1), object(26)\n",
      "memory usage: 273.4+ KB\n",
      "None\n",
      "          Timestamp  Age  Gender         Country state self_employed  \\\n",
      "0  27/08/2014 11:29   37  Female   United States    IL           NaN   \n",
      "1  27/08/2014 11:29   44       M   United States    IN           NaN   \n",
      "2  27/08/2014 11:29   32    Male          Canada   NaN           NaN   \n",
      "3  27/08/2014 11:29   31    Male  United Kingdom   NaN           NaN   \n",
      "4  27/08/2014 11:30   31    Male   United States    TX           NaN   \n",
      "\n",
      "  family_history treatment work_interfere    no_employees  ...  \\\n",
      "0             No       Yes          Often          WTD-25  ...   \n",
      "1             No        No         Rarely  More than 1000  ...   \n",
      "2             No        No         Rarely          WTD-25  ...   \n",
      "3            Yes       Yes          Often          26-100  ...   \n",
      "4             No        No          Never         100-500  ...   \n",
      "\n",
      "                leave mental_health_consequence phys_health_consequence  \\\n",
      "0       Somewhat easy                        No                      No   \n",
      "1                 NaN                     Maybe                      No   \n",
      "2  Somewhat difficult                        No                      No   \n",
      "3  Somewhat difficult                       Yes                     Yes   \n",
      "4                 NaN                        No                      No   \n",
      "\n",
      "      coworkers supervisor mental_health_interview phys_health_interview  \\\n",
      "0  Some of them        Yes                      No                 Maybe   \n",
      "1            No         No                      No                    No   \n",
      "2           Yes        Yes                     Yes                   Yes   \n",
      "3  Some of them         No                   Maybe                 Maybe   \n",
      "4  Some of them        Yes                     Yes                   Yes   \n",
      "\n",
      "  mental_vs_physical obs_consequence comments  \n",
      "0                Yes              No      NaN  \n",
      "1                NaN              No      NaN  \n",
      "2                 No              No      NaN  \n",
      "3                 No             Yes      NaN  \n",
      "4                NaN              No      NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Convert Age to numeric, coerce errors to NaN\n",
    "df_clean['Age'] = pd.to_numeric(df_clean['Age'], errors='coerce')\n",
    "\n",
    "# 2. Remove age outliers (keep ages between 15 and 80)\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[(df_clean['Age'] >= 15) & (df_clean['Age'] <= 80)]\n",
    "after = len(df_clean)\n",
    "print(f\"Removed {before - after} rows with implausible ages.\")\n",
    "\n",
    "# 3. (Optional) Check for duplicates and remove them\n",
    "dupes = df_clean.duplicated().sum()\n",
    "if dupes > 0:\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\"Removed {dupes} duplicate rows.\")\n",
    "\n",
    "# 4. Preview the cleaned data\n",
    "print(df_clean.info())\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d9fe6",
   "metadata": {},
   "source": [
    "## 2.3 Standardizing Gender Values\n",
    "\n",
    "In this section, we clean and standardize the 'Gender' column in our dataset. The original data contains many variations and misspellings for gender entries. To address this:\n",
    "\n",
    "1. We define a dictionary called `gender_map` that maps various possible gender responses to three categories: 'male', 'female', or 'other'. For example, entries like 'm', 'male-ish', and 'cis man' are all mapped to 'male', while 'f', 'woman', and 'cis-female/femme' are mapped to 'female'. Any entries that refer to transgender, non-binary, or other less common gender identities are mapped to 'other'.\n",
    "\n",
    "2. We then standardize the 'Gender' column by:\n",
    "   - Converting all values to strings,\n",
    "   - Stripping whitespace,\n",
    "   - Converting to lowercase,\n",
    "   - Mapping each value using our `gender_map` dictionary.\n",
    "   - Any value not found in the mapping is set to 'other' by default.\n",
    "\n",
    "3. We print the unique values in the cleaned 'Gender' column to verify the standardization.\n",
    "\n",
    "4. Finally, we save the cleaned DataFrame to a CSV file in the transformed data folder for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7d91d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Gender after cleaning: ['female' 'male' 'other']\n",
      "Cleaned data saved to ../data/transformed/OSMI_Mental_Health_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define a mapping for gender values\n",
    "gender_map = {\n",
    "    'male': 'male', 'm': 'male', 'male-ish': 'male', 'maile': 'male', 'mal': 'male', 'cis male': 'male', 'cis man': 'male',\n",
    "    'female': 'female', 'f': 'female', 'woman': 'female', 'cis female': 'female', 'cis-female/femme': 'female', 'femail': 'female',\n",
    "    'trans-female': 'other', 'trans woman': 'other', 'trans female': 'other', 'trans male': 'other', 'trans man': 'other',\n",
    "    'genderqueer': 'other', 'non-binary': 'other', 'agender': 'other', 'androgyne': 'other', 'other': 'other',\n",
    "    'fluid': 'other', 'queer': 'other', 'all': 'other', 'enby': 'other', 'p': 'other', 'a little about you': 'other',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# 2. Standardize the Gender column\n",
    "df_clean['Gender'] = (\n",
    "    df_clean['Gender']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .map(gender_map)\n",
    "    .fillna('other')\n",
    ")\n",
    "\n",
    "# 3. Preview the cleaned Gender values\n",
    "print(\"Unique values in Gender after cleaning:\", df_clean['Gender'].unique())\n",
    "\n",
    "# 4. Save the cleaned DataFrame to the transformed data folder\n",
    "output_path = '../data/transformed/OSMI_Mental_Health_Cleaned.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d162c",
   "metadata": {},
   "source": [
    "# 2.4 Standardizing Categorical Columns\n",
    "This section cleans up several categorical columns in the dataset. \n",
    "First, it defines a list of columns that contain categorical responses (like 'yes', 'no', etc.).\n",
    "For each of these columns, it converts all values to lowercase and removes any leading or trailing spaces, \n",
    "which helps ensure consistency (e.g., ' Yes ' becomes 'yes').\n",
    "\n",
    "Next, for columns that are expected to be binary (i.e., only 'yes' or 'no'), \n",
    "it maps any value that matches 'yes' or 'no' to itself, and leaves other values unchanged. \n",
    "This step helps to further standardize the data, making it easier to analyze later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb431420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of columns to standardize\n",
    "cat_cols = [\n",
    "    'self_employed', 'family_history', 'treatment', 'remote_work', 'tech_company',\n",
    "    'benefits', 'care_options', 'wellness_program', 'seek_help', 'anonymity',\n",
    "    'leave', 'mental_health_consequence', 'phys_health_consequence',\n",
    "    'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "    'mental_vs_physical', 'obs_consequence'\n",
    "]\n",
    "\n",
    "# Standardize to lowercase and strip whitespace\n",
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].astype(str).str.strip().str.lower().replace('nan', np.nan)\n",
    "\n",
    "# Optionally, map to only 'yes', 'no', or np.nan for binary columns\n",
    "binary_map = {'yes': 'yes', 'no': 'no'}\n",
    "for col in cat_cols:\n",
    "    df_clean[col] = df_clean[col].map(binary_map).fillna(df_clean[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663752a",
   "metadata": {},
   "source": [
    "# 2.5 Handling Missing Values in Categorical Columns\n",
    "This section deals with missing values in the dataset, focusing on categorical columns.\n",
    "\n",
    "1. For a set of binary/categorical columns (like 'self_employed', 'family_history', etc.), \n",
    "   the code checks the percentage of missing values. If less than 10% of the values are missing in a column,\n",
    "   it fills those missing values with the most common value (the mode) for that column. \n",
    "   If more than 10% are missing, it leaves them as missing for now and prints a message.\n",
    "\n",
    "2. For the 'state' column, any missing values are filled with the string 'Not US', \n",
    "   indicating that the respondent is not from the United States or did not provide a state.\n",
    "\n",
    "3. The code then checks all columns and drops any column where more than 50% of the values are missing, \n",
    "   as these columns are likely not useful for analysis.\n",
    "\n",
    "4. Finally, it prints a summary showing how many missing values remain in each column after these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c94ba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'self_employed' with mode: no\n",
      "Filled missing values in 'family_history' with mode: no\n",
      "Filled missing values in 'treatment' with mode: yes\n",
      "Filled missing values in 'remote_work' with mode: no\n",
      "Filled missing values in 'tech_company' with mode: yes\n",
      "Column 'benefits' has 32.6% missing; left as NaN for now.\n",
      "Column 'care_options' has 25.0% missing; left as NaN for now.\n",
      "Column 'wellness_program' has 15.0% missing; left as NaN for now.\n",
      "Column 'seek_help' has 29.0% missing; left as NaN for now.\n",
      "Filled missing 'state' with 'Not US'.\n",
      "Dropped columns with >50% missing values: ['anonymity', 'comments']\n",
      "\n",
      "Missing values per column after imputation and dropping:\n",
      "Timestamp                      0\n",
      "Age                            0\n",
      "Gender                         0\n",
      "Country                        0\n",
      "state                          0\n",
      "self_employed                  0\n",
      "family_history                 0\n",
      "treatment                      0\n",
      "work_interfere               262\n",
      "no_employees                   0\n",
      "remote_work                    0\n",
      "tech_company                   0\n",
      "benefits                     407\n",
      "care_options                 313\n",
      "wellness_program             187\n",
      "seek_help                    363\n",
      "leave                        560\n",
      "mental_health_consequence      0\n",
      "phys_health_consequence        0\n",
      "coworkers                      0\n",
      "supervisor                     0\n",
      "mental_health_interview        0\n",
      "phys_health_interview          0\n",
      "mental_vs_physical           574\n",
      "obs_consequence                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Impute binary/categorical columns with mode if only a few values are missing\n",
    "cat_cols = ['self_employed', 'family_history', 'treatment', 'remote_work', 'tech_company',\n",
    "            'benefits', 'care_options', 'wellness_program', 'seek_help']\n",
    "\n",
    "for col in cat_cols:\n",
    "    missing_count = df_clean[col].isnull().sum()\n",
    "    total_count = len(df_clean)\n",
    "    missing_pct = missing_count / total_count\n",
    "    # If less than 10% missing, fill with mode\n",
    "    if missing_pct < 0.1:\n",
    "        mode_val = df_clean[col].mode(dropna=True)\n",
    "        if not mode_val.empty:\n",
    "            df_clean[col] = df_clean[col].fillna(mode_val[0])\n",
    "            print(f\"Filled missing values in '{col}' with mode: {mode_val[0]}\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' has {missing_pct:.1%} missing; left as NaN for now.\")\n",
    "\n",
    "# 2. For 'state', fill missing with 'Not US'\n",
    "df_clean['state'] = df_clean['state'].fillna('Not US')\n",
    "print(\"Filled missing 'state' with 'Not US'.\")\n",
    "\n",
    "# 3. Drop columns with too many missing values (e.g., >50% missing)\n",
    "threshold = 0.5\n",
    "cols_to_drop = [col for col in df_clean.columns if df_clean[col].isnull().mean() > threshold]\n",
    "df_clean = df_clean.drop(columns=cols_to_drop)\n",
    "print(f\"Dropped columns with >50% missing values: {cols_to_drop}\")\n",
    "\n",
    "# 4. Show missing value summary after imputation\n",
    "print(\"\\nMissing values per column after imputation and dropping:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4cc44f",
   "metadata": {},
   "source": [
    "# 2.6 imputation of missing values\n",
    "This section handles further imputation of missing values. It first fills missing values in columns with moderate missingness ('work_interfere', 'benefits', 'care_options', 'wellness_program', 'seek_help') using the mode of each column. Then, for columns with high missingness ('leave', 'mental_vs_physical'), it fills missing values with the string 'unknown'. Finally, it prints a summary of the remaining missing values in each column after these imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'work_interfere' with mode: Sometimes\n",
      "Filled missing values in 'benefits' with mode: yes\n",
      "Filled missing values in 'care_options' with mode: no\n",
      "Filled missing values in 'wellness_program' with mode: no\n",
      "Filled missing values in 'seek_help' with mode: no\n",
      "Filled missing values in 'leave' with 'unknown'.\n",
      "Filled missing values in 'mental_vs_physical' with 'unknown'.\n",
      "\n",
      "Missing values per column after final imputation:\n",
      "Timestamp                    0\n",
      "Age                          0\n",
      "Gender                       0\n",
      "Country                      0\n",
      "state                        0\n",
      "self_employed                0\n",
      "family_history               0\n",
      "treatment                    0\n",
      "work_interfere               0\n",
      "no_employees                 0\n",
      "remote_work                  0\n",
      "tech_company                 0\n",
      "benefits                     0\n",
      "care_options                 0\n",
      "wellness_program             0\n",
      "seek_help                    0\n",
      "leave                        0\n",
      "mental_health_consequence    0\n",
      "phys_health_consequence      0\n",
      "coworkers                    0\n",
      "supervisor                   0\n",
      "mental_health_interview      0\n",
      "phys_health_interview        0\n",
      "mental_vs_physical           0\n",
      "obs_consequence              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Columns with moderate missingness: impute with mode\n",
    "moderate_missing_cols = ['work_interfere', 'benefits', 'care_options', 'wellness_program', 'seek_help']\n",
    "for col in moderate_missing_cols:\n",
    "    mode_val = df_clean[col].mode(dropna=True)\n",
    "    if not mode_val.empty:\n",
    "        df_clean[col] = df_clean[col].fillna(mode_val[0])\n",
    "        print(f\"Filled missing values in '{col}' with mode: {mode_val[0]}\")\n",
    "\n",
    "# 2. Columns with high missingness: fill with 'unknown'\n",
    "high_missing_cols = ['leave', 'mental_vs_physical']\n",
    "for col in high_missing_cols:\n",
    "    df_clean[col] = df_clean[col].fillna('unknown')\n",
    "    print(f\"Filled missing values in '{col}' with 'unknown'.\")\n",
    "\n",
    "# 3. Show missing value summary after final imputation\n",
    "print(\"\\nMissing values per column after final imputation:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949df37",
   "metadata": {},
   "source": [
    "# 3:  Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75ea08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age age_group\n",
      "0   37     35-44\n",
      "1   44     35-44\n",
      "2   32     25-34\n",
      "3   31     25-34\n",
      "4   31     25-34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bins = [0, 24, 34, 44, 54, 100]\n",
    "labels = ['<25', '25-34', '35-44', '45-54', '55+']\n",
    "df_clean['age_group'] = pd.cut(df_clean['Age'], bins=bins, labels=labels)\n",
    "\n",
    "print(df_clean[['Age', 'age_group']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bceefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned data saved to ../data/transformed/OSMI_Mental_Health_Final.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the output path \n",
    "output_path = '../data/transformed/OSMI_Mental_Health_Final.csv'\n",
    "\n",
    "# Save the DataFrame\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Final cleaned data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final cleaned dataset: (1250, 26)\n",
      "          Timestamp  Age  Gender         Country   state self_employed  \\\n",
      "0  27/08/2014 11:29   37  female   United States      IL            no   \n",
      "1  27/08/2014 11:29   44    male   United States      IN            no   \n",
      "2  27/08/2014 11:29   32    male          Canada  Not US            no   \n",
      "3  27/08/2014 11:29   31    male  United Kingdom  Not US            no   \n",
      "4  27/08/2014 11:30   31    male   United States      TX            no   \n",
      "\n",
      "  family_history treatment work_interfere    no_employees  ...  \\\n",
      "0             no       yes          Often          WTD-25  ...   \n",
      "1             no        no         Rarely  More than 1000  ...   \n",
      "2             no        no         Rarely          WTD-25  ...   \n",
      "3            yes       yes          Often          26-100  ...   \n",
      "4             no        no          Never         100-500  ...   \n",
      "\n",
      "                leave mental_health_consequence phys_health_consequence  \\\n",
      "0       somewhat easy                        no                      no   \n",
      "1             unknown                     maybe                      no   \n",
      "2  somewhat difficult                        no                      no   \n",
      "3  somewhat difficult                       yes                     yes   \n",
      "4             unknown                        no                      no   \n",
      "\n",
      "      coworkers supervisor mental_health_interview phys_health_interview  \\\n",
      "0  some of them        yes                      no                 maybe   \n",
      "1            no         no                      no                    no   \n",
      "2           yes        yes                     yes                   yes   \n",
      "3  some of them         no                   maybe                 maybe   \n",
      "4  some of them        yes                     yes                   yes   \n",
      "\n",
      "  mental_vs_physical obs_consequence age_group  \n",
      "0                yes              no     35-44  \n",
      "1            unknown              no     35-44  \n",
      "2                 no              no     25-34  \n",
      "3                 no             yes     25-34  \n",
      "4            unknown              no     25-34  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Columns in the final cleaned dataset:\n",
      "['Timestamp', 'Age', 'Gender', 'Country', 'state', 'self_employed', 'family_history', 'treatment', 'work_interfere', 'no_employees', 'remote_work', 'tech_company', 'benefits', 'care_options', 'wellness_program', 'seek_help', 'leave', 'mental_health_consequence', 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview', 'mental_vs_physical', 'obs_consequence', 'age_group']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the cleaned data (adjust if needed)\n",
    "cleaned_path = '../data/transformed/OSMI_Mental_Health_Final.csv'\n",
    "\n",
    "# Load the cleaned data\n",
    "df_final = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Show the shape and first few rows\n",
    "print(\"Shape of the final cleaned dataset:\", df_final.shape)\n",
    "print(df_final.head())\n",
    "\n",
    "# (Optional) Show column names\n",
    "print(\"\\nColumns in the final cleaned dataset:\")\n",
    "print(df_final.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
